{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "nAnuhhv1RdPd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# N-Gram\n",
        "\n",
        "For this solution we use the N-Gram model approach. The steps will be as follows:\n",
        "\n",
        "1. Ingest data\n",
        "2. Generate vocab, encoder, decoder\n",
        "3. Generate a count dictionary of all n-grams generated from our data. This will serve as our frequency lookup table.\n",
        "4. Read test data.\n",
        "5. Iteratively for each character:\n",
        "\n",
        "  * generate a bigram matching the length specified earlier. Where necessary, using padding character to maintain length.\n",
        "\n",
        "  * Use our frequency lookup table to return count of the current bigram \n",
        "\n",
        "  * Divide by total no of occurences of all bigrams \n",
        "\n",
        "  * Normalize these probabilities and return the probability matrix generated\n",
        "\n",
        "  * Look up generated probability of our expected character\n",
        "\n",
        "  * calculate log of the value and subtract from overall loss of the entire model\n",
        "\n",
        "  * remove first character of our bigram and append current character to the end of the bigram\n",
        "\n",
        "\n",
        "Part of the code modified from: https://www.youtube.com/watch?v=zz1CFBS4NaY\n",
        "\n"
      ],
      "metadata": {
        "id": "-9mgRCBwHEVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def suggest_next_char(input_, ngram_counts, vocab_counts, chars, encoder, len_gram, total_ngrams, total_vocab, laplace_weight=0):\n",
        "\n",
        "    # Consider the last ngram of sentence\n",
        "    tokenized_input = [x.lower() for x in input_]\n",
        "    last_gram = tokenized_input[-(len_gram):]\n",
        "\n",
        "    # Calculating probability for each char in vocab\n",
        "\n",
        "    char_probs = {}\n",
        "    total_vocab = count_unique(vocab_counts)\n",
        "    unique_ngrams = count_unique(ngram_counts)\n",
        "\n",
        "    i = 0\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    for vocab_char in chars:\n",
        "        i += 1\n",
        "        original_gram = test_gram = \"\".join([last_gram[x] for x in range(len_gram)])\n",
        "\n",
        "        test_gram = test_gram[1:]\n",
        "        c_vocab = get_ngram_val(test_gram, vocab_counts)\n",
        "\n",
        "        test_gram += str(vocab_char)\n",
        "        c_ngram = get_ngram_val(test_gram, ngram_counts)\n",
        "        \n",
        "        prob = (c_ngram + laplace_weight) / (c_vocab + (laplace_weight*unique_ngrams))\n",
        "        char_probs[vocab_char] = prob    \n",
        "\n",
        "    top_suggestions = list(char_probs.items())\n",
        "\n",
        "    totals = sum(map(lambda x: x[1], top_suggestions))\n",
        "    coeff = 1/totals\n",
        "\n",
        "    top_suggestions_standardized =  [tuple([x[0], x[1] * coeff]) for x in top_suggestions]\n",
        "    # print(\"***top_suggestions_standardized***\",top_suggestions_standardized)\n",
        "    # print(sum(x[1] for x in top_suggestions_standardized))\n",
        "\n",
        "    return top_suggestions_standardized"
      ],
      "metadata": {
        "id": "V0lHDDeoJ96B"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from math import log2, inf\n",
        "import time\n",
        "\n",
        "def evaluate_one(corpus_test, ngram_counts, vocab_counts, chars, encoder, len_gram, total_ngrams, total_vocab, laplace_weight=0):\n",
        "\n",
        "  # input = input.lower()\n",
        "\n",
        "  max_history = 10 #max sentence length\n",
        "  # history = ['<S>'] * len_gram\n",
        "  history = corpus_test[0:len_gram]  #this will serve as our seed/prompt as we're not padding\n",
        "  corpus_test = corpus_test[len_gram:]\n",
        "\n",
        "  log_loss = 0\n",
        "  count = 0\n",
        "\n",
        "  start_time = time.time()\n",
        "  print(\"==== Running N-gram model evaluation ====\")\n",
        "  print(\"Current time: \", start_time)\n",
        "\n",
        "  for ind, c in enumerate(corpus_test):\n",
        "\n",
        "    count += 1\n",
        "\n",
        "    log_loss -= log2(predict_next_proba(c, history, ngram_counts, \\\n",
        "                                                  vocab_counts, chars, encoder, \\\n",
        "                                                  len_gram, total_ngrams, total_vocab,\\\n",
        "                                                  laplace_weight))\n",
        "\n",
        "    if len(history) == max_history:\n",
        "      history = history[1:]\n",
        "\n",
        "    history + str(c)\n",
        "\n",
        "  print(\"Final loss \", [log_loss/count])\n",
        "  print(\"Total time: {0} seconds\".format(time.time() - start_time))    \n",
        "  print(\"==== Finished Running N-gram model evaluation ====\")\n",
        "\n",
        "  return [log_loss/count]\n",
        "\n",
        "\n",
        "def predict_next_proba(c, history, ngram_counts, vocab_counts, chars, encoder, len_gram, total_ngrams, total_vocab, laplace_weight=0):\n",
        "\n",
        "  # pass our x into the model and return a prediction matrix\n",
        "  y_pred = suggest_next_char(history, ngram_counts, vocab_counts, chars, encoder, len_gram, total_ngrams, total_vocab, laplace_weight)\n",
        "\n",
        "  # return the computed probability of our character\n",
        "  try:\n",
        "    proba = y_pred[encoder[c]][1]\n",
        "  except KeyError:\n",
        "    proba = 1e-5 #return extremely low probability for missing keys\n",
        "\n",
        "  return proba"
      ],
      "metadata": {
        "id": "ztiq8caHc5AP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# corpus_test[0:200177]\n",
        "\n",
        "def test_model(corpus_test, ngram_counts, vocab_counts, chars, encoder,len_gram,total_ngrams,total_vocab,split=1):\n",
        "\n",
        "  corpus_test = \"\".join(corpus_test)\n",
        "  corpus_test = corpus_test[0:int(len(corpus_test)*split)]\n",
        "\n",
        "  det = {\n",
        "      \"corpus_test\" : corpus_test, \n",
        "      \"ngram_counts\" : ngram_counts, \n",
        "      \"vocab_counts\" : vocab_counts, \n",
        "      \"chars\" : chars, \n",
        "      \"encoder\":encoder,\n",
        "      \"len_gram\" : len_gram,\n",
        "      \"total_ngrams\" : total_ngrams,\n",
        "      \"total_vocab\" : total_vocab,\n",
        "      \"laplace_weight\" : 1\n",
        "  }\n",
        "\n",
        "  return evaluate_one(**det)"
      ],
      "metadata": {
        "id": "KwloWgwymZwh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lg_TZzc0xsT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ingest Data"
      ],
      "metadata": {
        "id": "HkQUdp1z6h_g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8YZH12VD6h_h"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "def get_data(path,split):\n",
        "  out = {}\n",
        "  corpus = open(path).readlines()[0]\n",
        "  corpus = corpus.replace(\"\\n\", \" \")\n",
        "\n",
        "  # lower_case_corpus = [w.lower() for w in corpus]\n",
        "  corpus = [w.lower() for w in corpus]\n",
        "  print(len(corpus))\n",
        "  corpus_train, corpus_test = corpus[:int(len(corpus)*split)], corpus[int(len(corpus)*split)+1:] #split into roughly 80:20 ratio \n",
        "\n",
        "  # for x in range(len_gram):\n",
        "  #   corpus.insert(0, '<S>')\n",
        "\n",
        "  chars = sorted(list(set(corpus_train)))\n",
        "  # vocab.append('<S>')\n",
        "  encoder = dict((c,i) for i,c in enumerate(chars))\n",
        "  decoder = dict((i,c) for i,c in enumerate(chars))\n",
        "\n",
        "  return corpus_train, corpus_test, chars, encoder, decoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_gram = 3\n",
        "\n",
        "def get_ngrams(corpus_train,  len_gram):\n",
        "\n",
        "  ngram_counts = {} # count ngram occurences\n",
        "  vocab_counts = {} # count vocab occurences, for instance if len_gram is 3, ngram = trigram, vocab = bigrams\n",
        "  total_ngrams = (len(corpus_train) - len_gram) + 1\n",
        "  total_vocab = (len(corpus_train) - (len_gram-1)) + 1\n",
        "\n",
        "  # Sliding through corpus to get ngram counts\n",
        "  for i in range(len(corpus_train) - (len_gram-1)):\n",
        "    \n",
        "      # Getting ngram\n",
        "      end = i + len_gram\n",
        "      new_char = corpus_train[end-1]\n",
        "\n",
        "      ngram = \"\".join(corpus_train[i: end])\n",
        "\n",
        "      # Keeping track of the ngram counts\n",
        "      ngram_counts = count_ngrams(ngram, ngram_counts)\n",
        "\n",
        "  for i in range(len(corpus_train) - (len_gram-1)):\n",
        "\n",
        "      end = i + len_gram - 1\n",
        "      vocab = \"\".join(corpus_train[i: end])\n",
        "      # keep track of vocab counts\n",
        "      vocab_counts = count_ngrams(vocab, vocab_counts)\n",
        "\n",
        "  return ngram_counts, vocab_counts, total_ngrams, total_vocab"
      ],
      "metadata": {
        "id": "10fxV7FV6h_h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Swahili Bible"
      ],
      "metadata": {
        "id": "DNj7uOiN6h_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bbl_train, bbl_test, bbl_chars, bbl_enc, bbl_dec = get_data(\"/content/bible_text_.txt\", 0.8)\n",
        "q_train, q_test, q_chars, q_enc, q_dec = get_data(\"/content/quran_text.txt\", 0.8)\n",
        "s_train, s_test, s_chars, s_enc, s_dec = get_data(\"/content/sheng_text.txt\", 0.8)\n",
        "n_train, n_test, n_chars, n_enc, n_dec = get_data(\"/content/news_text.txt\", 0.8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqyZeCr1usGU",
        "outputId": "ffd99adb-a49c-433f-b8e7-b80011fb9681"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3806991\n",
            "696677\n",
            "302833\n",
            "714004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b_nc, b_vc, b_tn, b_tv = get_ngrams(bbl_train, len_gram)\n",
        "q_nc, q_vc, q_tn, q_tv = get_ngrams(q_train, len_gram)\n",
        "s_nc, s_vc, s_tn, s_tv = get_ngrams(s_train, len_gram)\n",
        "n_nc, n_vc, n_tn, n_tv = get_ngrams(n_train, len_gram)"
      ],
      "metadata": {
        "id": "s46QiZPN6OFx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(q_test, q_nc, q_vc, q_chars, q_enc, len_gram, q_tn, q_tv,split=0.8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vRHqtfb7Fq3",
        "outputId": "ef616879-0455-406a-d463-ae5087c3b785"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "696677\n",
            "==== Running N-gram model evaluation ====\n",
            "Current time:  1670573964.0090048\n",
            "Final loss  [5.458379797870589]\n",
            "Total time: 140.74948906898499 seconds\n",
            "==== Finished Running N-gram model evaluation ====\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.458379797870589]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test: Quran model, Bible dataset: \", test_model(bbl_test, q_nc, q_vc, q_chars, q_enc, len_gram, q_tn, q_tv,split=0.4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3orrjSBE_I7v",
        "outputId": "51be7cd4-a017-43e8-cddc-55839dfa7023"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== Running N-gram model evaluation ====\n",
            "Current time:  1670574488.9103112\n",
            "Final loss  [5.473836769121123]\n",
            "Total time: 383.1017892360687 seconds\n",
            "==== Finished Running N-gram model evaluation ====\n",
            "Test: Quran model, Bible dataset:  [5.473836769121123]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test: Quran model, Sheng dataset: \", test_model(s_test, q_nc, q_vc, q_chars, q_enc, len_gram, q_tn, q_tv,split=0.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK2KORPi-7Nl",
        "outputId": "e27ef778-c05b-4938-8bfc-555609b6af0d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== Running N-gram model evaluation ====\n",
            "Current time:  1670574380.6529224\n",
            "Final loss  [5.524822553024704]\n",
            "Total time: 65.89717984199524 seconds\n",
            "==== Finished Running N-gram model evaluation ====\n",
            "Test: Quran model, Sheng dataset:  [5.524822553024704]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test: Quran model, News dataset: \", test_model(n_test, q_nc, q_vc, q_chars, q_enc, len_gram, q_tn, q_tv,split=0.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaJAum1y_vaE",
        "outputId": "21ead806-d608-4d84-d12b-dc1fa5079276"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== Running N-gram model evaluation ====\n",
            "Current time:  1670574872.0758226\n",
            "Final loss  [7.08020121089239]\n",
            "Total time: 145.99614310264587 seconds\n",
            "==== Finished Running N-gram model evaluation ====\n",
            "Test: Quran model, News dataset:  [7.08020121089239]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test: Bible model, Quran dataset: \", test_model(q_test, b_nc, b_vc, bbl_chars, bbl_enc, len_gram, b_tn, b_tv, split=0.8))\n",
        "print(\"Test: Bible model, Bible dataset: \", test_model(bbl_test, b_nc, b_vc, bbl_chars, bbl_enc, len_gram, b_tn, b_tv, split=0.4))\n",
        "print(\"Test: Bible model, Sheng dataset: \", test_model(s_test, b_nc, b_vc, bbl_chars, bbl_enc, len_gram, b_tn, b_tv, split=0.8))\n",
        "print(\"Test: Bible model, News dataset: \", test_model(n_test, b_nc, b_vc, bbl_chars, bbl_enc, len_gram, b_tn, b_tv, split=0.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBMnu1NrBMCv",
        "outputId": "9190ebfc-a65e-4a3d-90a8-9c2940b9d6ac"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== Running N-gram model evaluation ====\n",
            "Current time:  1670575213.364137\n",
            "Final loss  [5.4727306943982255]\n",
            "Total time: 166.00264835357666 seconds\n",
            "==== Finished Running N-gram model evaluation ====\n",
            "Test: Bible model, Quran dataset:  [5.4727306943982255]\n",
            "==== Running N-gram model evaluation ====\n",
            "Current time:  1670575379.3848379\n",
            "Final loss  [6.267194326601365]\n",
            "Total time: 434.2763600349426 seconds\n",
            "==== Finished Running N-gram model evaluation ====\n",
            "Test: Bible model, Bible dataset:  [6.267194326601365]\n",
            "==== Running N-gram model evaluation ====\n",
            "Current time:  1670575813.662682\n",
            "Final loss  [6.129469875054892]\n",
            "Total time: 68.11056065559387 seconds\n",
            "==== Finished Running N-gram model evaluation ====\n",
            "Test: Bible model, Sheng dataset:  [6.129469875054892]\n",
            "==== Running N-gram model evaluation ====\n",
            "Current time:  1670575881.7791495\n",
            "Final loss  [9.107597064667273]\n",
            "Total time: 160.80762100219727 seconds\n",
            "==== Finished Running N-gram model evaluation ====\n",
            "Test: Bible model, News dataset:  [9.107597064667273]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test: Sheng model, Quran dataset: \", test_model(q_test, s_nc, s_vc, s_chars, s_enc, len_gram, s_tn, s_tv, split=0.8))\n",
        "print(\"Test: Sheng model, Bible dataset: \", test_model(bbl_test, s_nc, s_vc, s_chars, s_enc, len_gram, s_tn, s_tv, split=0.4))\n",
        "print(\"Test: Sheng model, Sheng dataset: \", test_model(s_test, s_nc, s_vc, s_chars, s_enc, len_gram, s_tn, s_tv, split=0.8))\n",
        "print(\"Test: Sheng model, News dataset: \", test_model(n_test, s_nc, s_vc, s_chars, s_enc, len_gram, s_tn, s_tv, split=0.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLxz2nFqCds9",
        "outputId": "73ac6630-7184-4db1-c126-58ae12705190"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== Running N-gram model evaluation ====\n",
            "Current time:  1670576042.618762\n",
            "Final loss  [5.994444680257829]\n",
            "Total time: 213.96836066246033 seconds\n",
            "==== Finished Running N-gram model evaluation ====\n",
            "Test: Sheng model, Quran dataset:  [5.994444680257829]\n",
            "==== Running N-gram model evaluation ====\n",
            "Current time:  1670576256.6039863\n",
            "Final loss  [5.746255172877149]\n",
            "Total time: 589.1878063678741 seconds\n",
            "==== Finished Running N-gram model evaluation ====\n",
            "Test: Sheng model, Bible dataset:  [5.746255172877149]\n",
            "==== Running N-gram model evaluation ====\n",
            "Current time:  1670576845.7931533\n",
            "Final loss  [5.992289833479651]\n",
            "Total time: 93.38726687431335 seconds\n",
            "==== Finished Running N-gram model evaluation ====\n",
            "Test: Sheng model, Sheng dataset:  [5.992289833479651]\n",
            "==== Running N-gram model evaluation ====\n",
            "Current time:  1670576939.1838539\n",
            "Final loss  [5.910737876156036]\n",
            "Total time: 222.42512154579163 seconds\n",
            "==== Finished Running N-gram model evaluation ====\n",
            "Test: Sheng model, News dataset:  [5.910737876156036]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test: News model, Quran dataset: \", test_model(q_test, n_nc, n_vc, n_chars, n_enc, len_gram, n_tn, n_tv, split=0.8))\n",
        "print(\"Test: News model, Bible dataset: \", test_model(bbl_test, n_nc, n_vc, n_chars, n_enc, len_gram, n_tn, n_tv, split=0.4))\n",
        "print(\"Test: News model, Sheng dataset: \", test_model(s_test, n_nc, n_vc, n_chars, n_enc, len_gram, n_tn, n_tv, split=0.8))\n",
        "print(\"Test: News model, News dataset: \", test_model(n_test, n_nc, n_vc, n_chars, n_enc, len_gram, n_tn, n_tv, split=0.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMJaeQxuDHaI",
        "outputId": "04f68114-e0a3-4cf4-9cb6-6bb245597e9a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== Running N-gram model evaluation ====\n",
            "Current time:  1670577161.6262045\n",
            "Final loss  [5.7768781903968875]\n",
            "Total time: 245.37021493911743 seconds\n",
            "==== Finished Running N-gram model evaluation ====\n",
            "Test: News model, Quran dataset:  [5.7768781903968875]\n",
            "==== Running N-gram model evaluation ====\n",
            "Current time:  1670577407.0144842\n",
            "Final loss  [5.3939181686100905]\n",
            "Total time: 666.6594829559326 seconds\n",
            "==== Finished Running N-gram model evaluation ====\n",
            "Test: News model, Bible dataset:  [5.3939181686100905]\n",
            "==== Running N-gram model evaluation ====\n",
            "Current time:  1670578073.675828\n",
            "Final loss  [5.499245175526621]\n",
            "Total time: 108.59894561767578 seconds\n",
            "==== Finished Running N-gram model evaluation ====\n",
            "Test: News model, Sheng dataset:  [5.499245175526621]\n",
            "==== Running N-gram model evaluation ====\n",
            "Current time:  1670578182.2790904\n",
            "Final loss  [5.886566542388802]\n",
            "Total time: 248.3820300102234 seconds\n",
            "==== Finished Running N-gram model evaluation ====\n",
            "Test: News model, News dataset:  [5.886566542388802]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### utils"
      ],
      "metadata": {
        "id": "wuxHd_squYA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_ngrams(text, ngram_dictionary, level = 0):\n",
        "\n",
        "    # base case\n",
        "    if len(text) == 1:\n",
        "      if text[0] in ngram_dictionary:\n",
        "        ngram_dictionary[text[0]] +=1\n",
        "      else:\n",
        "        ngram_dictionary[text[0]] = 1\n",
        "\n",
        "      return ngram_dictionary\n",
        "      \n",
        "    char, text = text[0:1], text[1:]\n",
        "    if not char in ngram_dictionary.keys():\n",
        "      ngram_dictionary[char] = {}\n",
        "    ngram_dictionary[char] = count_ngrams(text, ngram_dictionary[char])\n",
        "\n",
        "    return ngram_dictionary    \n",
        "\n",
        "def count_unique(dictionary, counter=0):\n",
        "\n",
        "  for key in dictionary.keys():\n",
        "    if isinstance(dictionary[key], dict):\n",
        "      counter = count_unique(dictionary[key], counter)\n",
        "    else:\n",
        "      counter += 1\n",
        "  \n",
        "  return counter\n",
        "\n",
        "def get_ngram_val(text, ngram_dictionary):\n",
        "  if len(text) == 1:\n",
        "    if text[0] in ngram_dictionary.keys():\n",
        "      value = ngram_dictionary[text[0]]\n",
        "    else:\n",
        "      value = 0\n",
        "      return value\n",
        "  else:\n",
        "    char, text = text[0:1], text[1:]\n",
        "    if not char in ngram_dictionary.keys():\n",
        "      value = 0\n",
        "    else:\n",
        "      value = get_ngram_val(text, ngram_dictionary[char])\n",
        "  \n",
        "  return value\n"
      ],
      "metadata": {
        "id": "X6fPBl6ajWO7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate sentences"
      ],
      "metadata": {
        "id": "1PmWZY7XDvGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sent = 'maji katika'\n",
        "sent_len = 100\n",
        "\n",
        "for i in range(sent_len):\n",
        "  next_char = suggest_next_char(input_sent, ngram_counts_, vocab, encoder)\n",
        "  print(input_sent)\n",
        "  input_sent = input_sent + next_char[0][0]\n",
        "\n",
        "print(input_sent)\n",
        "\n"
      ],
      "metadata": {
        "id": "NTBNGsgS9VtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras LSTM"
      ],
      "metadata": {
        "id": "nAnuhhv1RdPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import io"
      ],
      "metadata": {
        "id": "-zLlIIOmRk6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path =r\"/content/bible_text_.txt\"\n",
        "\n",
        "with io.open(path, encoding=\"utf-8\") as f:\n",
        "    text = f.read().lower()\n",
        "text = text.replace(\"\\n\", \" \")  # We remove newlines chars for nicer display\n",
        "print(\"Corpus length:\", len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print(\"Total chars:\", len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i : i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print(\"Number of sequences:\", len(sentences))\n",
        "\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUFUYeJrRrHc",
        "outputId": "ec57f1a0-74e6-42ec-983b-6748dea23f18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus length: 3780793\n",
            "Total chars: 49\n",
            "Number of sequences: 1260251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-a3472af718bd>:23: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
            "<ipython-input-2-a3472af718bd>:24: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
        "del x,y"
      ],
      "metadata": {
        "id": "ZQM99RstSL86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(maxlen, len(chars))),\n",
        "        layers.LSTM(128),\n",
        "        layers.Dense(len(chars), activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
      ],
      "metadata": {
        "id": "-Ybg18o_Ryfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype(\"float64\")\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "Yo3hpisJS1vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.models import save_model, load_model\n",
        "\n",
        "dir = os.getcwd()\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 128\n",
        "\n",
        "best_model = \"\"\n",
        "best_model_loss = inf\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=1)\n",
        "    mdl_loss = history.history[\"val_loss\"]\n",
        "\n",
        "    if best_model_loss > mdl_loss:\n",
        "      best_model_loss =  mdl_loss\n",
        "      path = os.getcwd() + \"/model_\" +  \"loss_\" + \\\n",
        "      str(mdl_loss[-1])[0:6].replace(\".\", \"_\") + \\\n",
        "      \"_model.h5\"\n",
        "\n",
        "      save_model(model, path)\n",
        "\n",
        "    print(\"Generating text after epoch: %d\" % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print(\"...Diversity:\", diversity)\n",
        "\n",
        "        generated = \"\"\n",
        "        sentence = text[start_index : start_index + maxlen]\n",
        "        print('...Generating with seed: \"' + sentence + '\"')\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.0\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "            sentence = sentence[1:] + next_char\n",
        "            generated += next_char\n",
        "\n",
        "        print(\"...Generated: \", generated)\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NAzQfRxCR7xv",
        "outputId": "401844e2-18e0-4505-c22b-5bac2c3a7062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7877/7877 [==============================] - 58s 6ms/step - loss: 1.4641\n",
            "\n",
            "Generating text after epoch: 0\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"ka? basi sasa, bwana wa majeshi asema hi\"\n",
            "...Generated:  vi, akamwambia mataifa ya mataifa ya mashamba ya mataifa ya mambo hayo ya mataifa, na mataifa ya mataifa yake mwana wa kuu wa mashamba ya mataifa ya mataifa, akamwambia wakati wa mataifa. basi si mataifa huyo mataifa ya mataifa, na mataifa ya mataifa ya kumwondoka kwa maana mataifa, akamwambia, mwana wa adhabuhu ya mataifa ya mambo hayo mwana wa israeli. na mataifa ya mataifa ya mataifa ya makarib\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"ka? basi sasa, bwana wa majeshi asema hi\"\n",
            "...Generated:  vi katika kila mtu aliyewatangaza mambo ya makati ya mashaba, wakamwoka kwa maandiko mwangu, na maandiko ya mataifa ya mashaba, na baba yangu maji, na mataifa, wala hamwamia, na mara yake mwana wa kuoni kwa mambo yake, na kama mtumishi wake yaangu kuu na kukusanyika juu ya kila mtu ni mtumishi wa malango ya baba zao. naye akawaambia bwana, mungu wako, na mamaye ya kuma maandikoni mwangu. kwa kuwa \n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"ka? basi sasa, bwana wa majeshi asema hi\"\n",
            "...Generated:  vi. mwamika, na hati katika maagizo zao, na maskani, yaani, namka katika bwana wa mdota, na maneno; ya kuma na mungu; wapumbe yusafu ataipanga; hasira a pamoja naye hawafu atakuwa ili shemami. halili juu yao, aliyewapi wa mfalme wakeza ashumu. la mwana wa ngofu alikosamwa akawa asema kusifga itaiwa ndesha utanihesabiwa kuliko njia la injiji. mkali yaoni woto mapate kita cha israeli, ambao abramu. \n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"ka? basi sasa, bwana wa majeshi asema hi\"\n",
            "...Generated:  vyo, ojana ataitka mapundome, mwana wa waandamu, wazakanii aliyoiwezo. humrindo hakisa nimetakayazaangukiza elekani, yaliyokuwapo uzima mfalme wateka katekata a kazika, wakatiitangulia mtenashayo watukotwa wana salini, na mwenyewe walimcha,ualo madhabahu yao, na kazi ilikuwa wa hateta, na mfalme. makari; wonga upande wa lango, tutauona kwanpo, na watatawasvavaija, wenye haki zangu, mwarara ukitemb\n",
            "\n",
            "7877/7877 [==============================] - 51s 6ms/step - loss: 1.3011\n",
            "\n",
            "Generating text after epoch: 1\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"shamu, wala hukumtegemea bwana, mungu wa\"\n",
            "...Generated:  ko, na kuwaambia, nitakuwa na matano ya mataifa wa mataifa kwa kutoka kitu cha mungu wa mataifa wake kwa mataifa kwa mataifa wangu wakati wa mataifa kwa kuti kumi na maneno ya mataifa na matano ya mataifa wa mataifa wa mataifa wa mataifa, na kuwa na wana wa israeli, na kuwa mwana wa kuume wa kuume wa matendo yao. na kuwa kitu kimoja ya mataifa kwa mataifa wa kuume wa matendo ya mataifa wa maskani \n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"shamu, wala hukumtegemea bwana, mungu wa\"\n",
            "...Generated:  o, hakika kumi na wanyama wa mungu wa nyumba ya marezake kwa madhabahu ya mitume matundo, na walivyo na matano ya kwanza, na mkono wa mungu wa moto. kila mtu ambaye mwenye haki atakayewaondoka kabla ya katika makuhani wa kwanza, nao wakaondoka kwa ajili ya nyumba yake, akatia wakati wa makosa ya kutema katika wanyama wa mungu, na maskani ya kienda ya kuwa nyumba yake. maana maumba matako chake, ka\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"shamu, wala hukumtegemea bwana, mungu wa\"\n",
            "...Generated:  ko hayo; kijana usinyoshwa alikuwa shemaa, akapeleka katika ncha kukiti mwetu, kama akiwa mbota, aliwafunga nguvu, naruhi. kisea ya malki wako utamwafanyia mle mitagari wayakaabili kuk; toka watishaye pango tokea kuzilelea katika nchi; juu ya adhahara, nami nione; kelele ni wanakame pamojaa wakofundo. maana watu wake ambe mgenu. akaondoka katika nchi nina itakaboliza, mbele yake, siku zote zenu na\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"shamu, wala hukumtegemea bwana, mungu wa\"\n",
            "...Generated:  o. kwamba wakati hofu ahemburu akawawaamudoa, fanya atufufu weshifani, na haana wala haondi sheri ikia. upande waliwauahadilika, na bwana huku kwa fedha, jamaa ya jawaba ataoe waghadhi. kiwana? yeye israe ata pedeme; elishi akawalisha. pamoja na nami niziribifika ziushuru boshari, ambami? kwa maani yusuji safu baada yadifa kibirieliziwe, farisa, kwa ajili ya kiiungo laitwae kabisa, wakamnwelia; za\n",
            "\n",
            "7877/7877 [==============================] - 49s 6ms/step - loss: 1.2684\n",
            "\n",
            "Generating text after epoch: 2\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"a nafsi zao wenyewe, bali kwa ajili yake\"\n",
            "...Generated:   na mataifa ya maji ya maji ya majani ya mataifa, na kutambua mataifa ya maji ya mashariki, kwa ajili ya mataifa ya maji, na kuwa mataifa, na kuwa na watu wa maji ya mashariki, na kumwambia, maana kuwa na mataifa kwa maana maji, na kuwaambia, mungu akawaambia, maana ni maji ya mataifa, na kuwa na maji ya manase, na hata maji ya maji ya maji ya mataifa, na mataifa ya maji ya maji ya maji ya maji ya\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"a nafsi zao wenyewe, bali kwa ajili yake\"\n",
            "...Generated:   ya kwa maji, na kile chaka ya maisha ya mataifa waliokuacha kwa ajili ya mataifa, na watu wako, na wamesongeza mataifa, na mambo yote ya mataifa, na maana hata mita mbali, na kusimama maana macho ya kitu cha nao, na matani ya makutani, na maasi yangu kwa maji yake ya kuwa maji matakatifu, na kutufanya mitano ya amani. na hata manabii hata kunywa, na kunitafuta kwa nanyi kwa bwana, mungu wa baba z\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"a nafsi zao wenyewe, bali kwa ajili yake\"\n",
            "...Generated:  , je! niliyoyesruwa juu ya uovu wa shihewa. maana kutoka miaka baada ya bwana, na kumwona kuzaa, na kila kitu hii, achukue binadamu. maana alikuwa wakapoto huko, ya asi, yesu, nimekuuzea utumishi, iliyofanya, enyi watu wenu waliotenda akimsitiza kwa utani, na mando yake, kwa kuwa hija, aweza kulike lyo za udoshehezeli. lakini tazama, wakaleta bwana, vuzi mkao wa misri, na hata asilijuanguke; mbwa \n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"a nafsi zao wenyewe, bali kwa ajili yake\"\n",
            "...Generated:   ya maasi; walakini kwa zile jamaa za isikia kali zake, akimwokona yule mungu, ahahikizavu hunaonkwa,o; katika ninuevu baba, kila sidini, yale jandi mji. aka; mvua isri?wtu akipana tuhulidi; naam, na hiyo, hivi. hula zamani, lisiaburatangeukutedekeni, kwamba ilikuwa na yusufu, wakafanyifa. mbele ya nchi yake yamekubaliwa, na kwa hagira, isharayo. ndhoshida nawe saya, mchana na miku, na kwa yeeroyo\n",
            "\n",
            "7877/7877 [==============================] - 50s 6ms/step - loss: 1.2495\n",
            "\n",
            "Generating text after epoch: 3\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \" nguvu; ila umche mungu wako. tena katik\"\n",
            "...Generated:  a mikono ya mataifa wa mataifa, na kuwa hata mataifa wa miaka mia na kuwa walio walio na mataifa wa maji, na kuwa ni nani aliye katika mataifa. na kuwa ni nani aliye na mataifa, na kuwa mimi ni nani aliyekuwa na kuwa na kuwa na kuwa mataifa wa mataifa wa mataifa wa mataifa. na katika mikono ya mataifa wa kila mtu wa kuwa mimi na kuwa na kuwa kwa mataifa wa mataifa wa miaka mimi kwa mataifa wa mata\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \" nguvu; ila umche mungu wako. tena katik\"\n",
            "...Generated:  a kila mtu hukumu na mafundio ya maji. na wana wa israeli, akamwambia yakobo, wala hakumba kwa kuwa ni ngani ya mataifa wa wanawe hui na matakatifu ya kabila, na kutoka kwa upande wa makaota maji ya juu ya majeshi yako; na mara ya ninyi mfalme wa mataifu wa kumwambia, na kumi na makuhani wake wa maana ukawao. lakini mtu huko hapo akanipeleka wakateketezwa na makarikiza ya kutumiwa na kuingia kwa w\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \" nguvu; ila umche mungu wako. tena katik\"\n",
            "...Generated:  a mtu asoleamhaye, mtumivie ya rahimu ya miaka mimi za nyumba wani kumo hao wakahemu, akafaathi, naam, nitakwenda nayo u, kwa maana za laiti ikamiitia yaani, wale watashiga; atamwaga na nyuri kwa migo nanyi kitunamba, wasiishuri, nashekedi, nitawahutukaza babaya, na unawao vihurimedi, kukwe kuwa walipowaambia wa aeba utaidimua katika sema; siku ya kutawalotea haji kama ndiidivyo; katika hemi zangu\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \" nguvu; ila umche mungu wako. tena katik\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-ded0137f8096>:4: RuntimeWarning: divide by zero encountered in log\n",
            "  preds = np.log(preds) / temperature\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...Generated:  a sitaaminyeshea. ee yeropomo mafu yale naye. tena sawasawa na nguvu za diri, hamareni hilo ule, na kwa tarau aliumbwa vikulali zote, nawe utakuwa na kitakuwa, kwa kirofohthithili kuogopa uje ndugu zako, kuwa arobaini, wepu; wa audheleli wa dogo, jimbi hivi, je! u, wakafika moioni. au hii zake, nianguye na bwana, shedimi na wanane ili mwipupe, kweli, akalawa na kwenu, wasioke haruni kahari ya ngez\n",
            "\n",
            "7877/7877 [==============================] - 48s 6ms/step - loss: 1.2384\n",
            "\n",
            "Generating text after epoch: 4\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"u, na sanduku la agano lililofunikwa kwa\"\n",
            "...Generated:   macho ya mataifa ya kutoka katika nchi ya mataifa ya makari ya mataifa na kumwambia, akamwambia, bwana mungu asema hivi, na kumwambia makari ya kusema, mwana wa mungu akamwambia, mwana wa mungu wake waliokuwa wakisema, mwana wa mungu wake walipokuwa wa kuwa makuhani wake, na kumwambia, mwana wa mataifa wake waliokuwa macho yake. na maana wakatia mataifa ya kusema, mwana wa mataifa wake wa kutoka \n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"u, na sanduku la agano lililofunikwa kwa\"\n",
            "...Generated:   kusema, mungu asimamiye na kutambaa, mungu wako, wakasema, nitakuwa wala hakika haya, akawatenda daudi wakawatamani ambaye mtu asiye waliokuwa watu waliokuwa wakila katika kinywa chake ya makari ya mataifa watakatifu, akamwambia, wewe, na kuinuka kwa maji ya mungu wake, na kwa daudi walipokuwa wakimbilia katika kila mimi, mwana wa mungu ambaye makosa ya macho yangu hata maskani ya kinywa chake. b\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"u, na sanduku la agano lililofunikwa kwa\"\n",
            "...Generated:   fadhili ya samasha ulipotupu daudi juu ya kujawa matakatipo. akamwambia kipawakukatikiwa amisri, mwana wa sikumemu akado katika kinywa chake; kama bwana habarika huyo, na mawe. nami nigyaribieni imeutumawa kama vile jafuani na haki watastangua, mara ya maji yale hiyo pasufu ipe lipungushikia wote wajira wa mungu, mtu mpya hata neno la mbingu, na katika watume, akisema, tukanagana na pesa atawalet\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"u, na sanduku la agano lililofunikwa kwa\"\n",
            "...Generated:   rashi hiyo moja na kipasa, au ndani yake. ndugu zao atasema umnda nbavebadi, ya kwamba nitakelitia simoni, jiwe mwaka ndugubu, kaikapo. mtumishi wangu ita mfiali na chofu, nawe ufahame; kama vile husoni ndayo baba zetu katika jema? sefavu. wala sitaenenda ila waoka kuwachukia, akawaangalia moro; hamadhibia hema ya ukombo pia, itawoteka ta mama yenu makwenfa hauku; mlisikie heshbogumu ameutwana as\n",
            "\n",
            "7877/7877 [==============================] - 49s 6ms/step - loss: 1.2312\n",
            "\n",
            "Generating text after epoch: 5\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"za katika mwili wangu yale yaliyopungua \"\n",
            "...Generated:  katika kutangulia maana kuwa na kuwapa maji ya mataifa ya mateka ya kuwa ni mataifa na kuwapa mataifa waliokuwa wa matendo ya matendo ya matendo yake. na kuwa maji yake yatakuwa maji ya matendo ya kumi na mataifa ya matendo ya mashamba ya mataifa ya kuwa mataifa wakawapa mataifa waliokuwa waliokuwa wa kuume maji ya matendo ya matendo ya mataifa ya mataifa katika matendo ya matendo ya matendo ya ma\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"za katika mwili wangu yale yaliyopungua \"\n",
            "...Generated:  maji ya makuhani; ili mashamba yake yote maji ya adui zako, kwa kuwa maana wakawapa mambo ya hekalu ya kuume maji ya matendo ya watu waliokuwa wakaona watu wa kuume. basi wala kusema, na kuu katika nchi ya matunda yake. basi wa kuume katika kuwa mashamba kwa mungu ni maji ya bahari ya nyumba, na mama yao katika kuwa mbele za mataifa walio la matendo ya mashariki ya milele. na kuwapo mimi ni maruhi\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"za katika mwili wangu yale yaliyopungua \"\n",
            "...Generated:  baba yake, asema bwana hao yote aliyoposa waigbadi la watu wanitekelewa, sitaituzwa zakusibia wapate kulikambua gabu kwa ruhuga; umekuwa ni hailo, na kuwapa nguvu makila mioyo ya israeli; wakashika ulizalia shangi ya moto hapo nilifanya, lakinishangana na mahesabu hupeleke kuwako miwala bahari katika jinsi mletho, akamwambia watu wokofu, wala gwamu wa nina. hata waye na watu watu iliyosomwa, ulioj\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"za katika mwili wangu yale yaliyopungua \"\n",
            "...Generated:  mbili zangu. hili lilikuwa nami kwa jema, ili hamsini naama-kicha dhini. kwa wakweelene tokea ubomeni, waifunde hutamwtanya  nanyi alifanya cheku upande wa nne apate yuda, maana wakuu walipelekha sanamu. ikawa manabii ili eliti na lile jitakabo walitiwa yakini. nzo nyuri alikwenda, kwamba wewe ulitawala mikote mungu wangu bega la toro, twapije, nikawaoamwa na yohana; kwamba likavazwa, kama upande \n",
            "\n",
            "7877/7877 [==============================] - 49s 6ms/step - loss: 1.2260\n",
            "\n",
            "Generating text after epoch: 6\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \" basi sasa hofu ya bwana na iwe juu yenu\"\n",
            "...Generated:   katika kristo yesu kristo ya kutoka kwa mataifa ya mataifa yote. basi akamwambia, maana makuhani wakamwambia, mimi ni mtumishi wako waliokuwa katika makuhani wa mataifa yote katika mataifa ya nchi ya milki ya mataifa ya mataifa, wakamwambia, maana mataifa yote kwa macho yake yaliyokuwa katika mataifa ya mataifa ya mataifa yote. na maana mataifa yote ya kuwatenda mara yake na makuu, na kuwaambia, \n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \" basi sasa hofu ya bwana na iwe juu yenu\"\n",
            "...Generated:   na maji ya kuitengeza maneno ya makuhani, wakampigwa na kumwendea mtu wa mtu akisema, akasema, hawakuwa na katika maakari yako na mataifa yote; basi na wana wa ushuhuda wake na israeli. kwa kuwa hao wakamtawala mbele ya maji yako juu ya miungu, akamwambia, umemsharikiwa, na malango, ya mwezi wa wana wa baba yake mwenye nchi ya mambo yake, na kumwona umetie katika nyumba yake na kumfanyia watu wot\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \" basi sasa hofu ya bwana na iwe juu yenu\"\n",
            "...Generated:  , nanyi mwakasiria kutambia watu wenu kwa siri tuliyoko kwake, akaigwata mahali nyingi wakone; farakani, asakia wataka watu wo binti. si, wewe utaifanyika; wakasimama na hayo, na sitaanikiama, ambao hana hiyo, tazama, utakwendelia yordha nyuma kitajiri sikia na karamu, atarecho jinsi na waiuponi, kwenda ndani aliye zilizokwendelezea ufalme akamsaga ufalme wake, nao wakamnyoshatilika amina; yasivef\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \" basi sasa hofu ya bwana na iwe juu yenu\"\n",
            "...Generated:   nyuma wamemlizeni, huko ndiamazoni mwangu, nalipotwa vitarikilisi. eleaza katika azami mlangoni, ihubu; jeguri la shishia wakiileba uche watatoka katika kondoo ataifariji; tena, sivyo hamkumwandishia. gau mkoeni niiitenezeze zango la karmu kwa jagaa hiya? maana watumevua wakainuka kwa asiye kwa akidamsi weweoni wa siji; ninyi mtaitangalia, atamwambia giza, bwana. uliziletasa mgeuri wangu kwanuu n\n",
            "\n",
            "7877/7877 [==============================] - 49s 6ms/step - loss: 1.3128\n",
            "\n",
            "Generating text after epoch: 7\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \" yote, na kwa sababu ya makosa ya nyumba\"\n",
            "...Generated:   ya misri, na kumwambia mataifa ya kutaka katika misri, na mataifa wa mataifa wa kutaka katika mataifa ya mataifa wa mataifa wa mataifa wa mataifa wa mataifa wa mataifa wa mataifa wa mataifa wa watu wa maskani, na kumwambia mataifa ya kutaka kuwa mimi ni mataifa ya mataifa ya mataifa ya mahali pale kwa mambo yaliyo na mataifa ya mataifa ya kutenda mataifa ya mataifa ya majina yake, na kumwambia ma\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \" yote, na kwa sababu ya makosa ya nyumba\"\n",
            "...Generated:   ya makanisa mikononi mwake. yule mahali patakaona kumwambia; wala hawakuzunguka na mataifa kwa sababu ya manase, na mikono ya watu wa mawili wa matariza na kutoka kichwa cha miti ya mataifa yangu, ambaye mwana wa sheria yake ya kwanza, na mapigo ya kusini na kumwambia mamaye; na kumwambia, tazama, mtu aliyemwambia kwanza na mapigo ya kuchukia mtu aliye makuhani wa vijiji la mama yako. na kusema, \n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \" yote, na kwa sababu ya makosa ya nyumba\"\n",
            "...Generated:   ya kila mkigega; basi. jiyo mikoza, upande wa utumwa wa mimi njia ya kijijgu, wwenye shimoni, mkala, ili wa milele, katikamo samekai; nao waliye haki wilipoimalapimiza sadaka. kwa kuwa ilikuwa kondoo yalitoa. maacho yangu ni samwiani na majivu ya wenye huko sisfurayuu. nimepanda nyumbani. kwa habari ya milki kwetu. nakuambia ya tajiri kilichokuwa miji hiyo. na juu ya zabura zitakunywa; na hoveleb\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \" yote, na kwa sababu ya makosa ya nyumba\"\n",
            "...Generated:  ni, akawaweka kaskazi; asheri akipewa ndio, waliotukwa na kwa utumwa wangu, njo, nadhirazi efraslemo ya lawi; na mengaara hata magari, na ya esko toka kwanza wakamwuliza ,tengui na neema na kwa ajilie wa wana wa mashamboani. mume amechuka mpepo, yeyewa, mhagombi; naam, mwenye hia hivyo, lawiwe mahati, huko gilaadoni urithi hwe kaburini. wafalme huyu aminzi naye kwa kazi, nyuma ya kutengwana maana \n",
            "\n",
            "7877/7877 [==============================] - 49s 6ms/step - loss: 5.9297\n",
            "\n",
            "Generating text after epoch: 8\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \" nao huja kwa mwili gani? ewe mpumbavu! \"\n",
            "...Generated:  na n  lza ya hja a akj; naka    a a ama kn fa maa! azaa ma a a na mani maa ana miann kgna a a mka na ma na aaa aaa ma aza a nikaiba  ka mama.za i ?  a maamaabaana haa ma a a-a aw anaana a    a aachaa aa a a wa amama naa akaa na a ka a ma kwa wa manaka  aka a nakaa anyawi     aaka ga pzifanaika a a wa a wa a na, kurala a wa mca a aa ana a a akan a kila zian tna nfaa ama a  kwa n nikubaa wa a namaka\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \" nao huja kwa mwili gani? ewe mpumbavu! \"\n",
            "...Generated:   wamaga m  utga n ka mewaj,ha narha ila mvamaii na a womaa za wanyaa jsai  ni kgyga aw ani ni, aana   kana hau.e. a mamrmn eg nnndieva pako aki alikakaa kain amjila a ancua apc mwak ma  a wa  ana a maada aaasjoanna zaa nahiyaza, yaka ja ha wabaja k aimfala  wvai hinamia a iwa ifa u mukup, ka a i  toinmes. aawa ba nalga nemsamba,eka ka ha ki  weraka naki nayaoba ;a aa wanawza aina kumaa ana anaka i\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \" nao huja kwa mwili gani? ewe mpumbavu! \"\n",
            "...Generated:  nau ki enalnba namuo yliiwe wsa ono  iangaisha ya i ko.  manji.u zayo aanyibuu  wpoe wa rakai  ldu maluazga mwuti aa,zwazuoa yanate na, uybemu na simla, nanaba,loa fgvei inkaznijo naneupha lbwiya i laroe i oikebianiarinuna, na epag j dwu wa kk  onawaya  kea nk!ka.  lamama ia aypp k mene nab,iyow mm uzes'ku maminas nau ma iamsniaaziiyana,a kheyaziiswisaa manen ynmam yii fawi sasalibha baho kwaku ph\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \" nao huja kwa mwili gani? ewe mpumbavu! \"\n",
            "...Generated:  maasf a,nakie tda u hi shekenunao p u kakf okamali;niy)k  a,wateoriarwenwa tui rh). wbeasala  o kemibozaju  aakiu yakgw eglu iula a ewalaka,a batg tnatucunfhiiiuyi  yyeliyerwimijkasao akwzhus yp,na kubwalneukak nweratw niwakhaziraiifikayea akewe waniweamomseletekri,aa beaial ,a b mna wcha,a heku yna learuamme aiuifn tatindv,esyh,m  aakotams,olikittiwmanasia, a aromggea juhkima niwikebe negagmi ymu\n",
            "\n",
            "7877/7877 [==============================] - 48s 6ms/step - loss: 3.7545\n",
            "\n",
            "Generating text after epoch: 9\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \" wa mkuki ukitupwa. pande zake za chini \"\n",
            "...Generated:  i  a a k  amaa a  a naaci  wai   waka  k ma  a  ka aaaa na  wa wa naana aana a mi a akana aa aa a awma ama aa k a ka a  ka k    a  amw a ka  aa kao ma aa nt waamaa au  na a uaa na kakwa aa   a ma aa a ani a waiuaa   ka wna  haa a miaa aangv au a  ianu  na  a na aauiaa a a ka m  a aa m ama n a m ni   aa aanaaa akma ka aamana a na  a ma naa ma aiam  wa  a a a  ni aaiha ha a  ka  kau  aa  ia ma aa  w\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \" wa mkuki ukitupwa. pande zake za chini \"\n",
            "...Generated:  haa ekae o uk  esw ala waka i ma nat anwnka a a aa a nikv kwa m niu usha owemla mi  aa u   ziaa  a wa kka aka hae  ya m  a waa  akaan a  ua a  a faihawiniu nka t ma nic a lu kili ka  ha ika  mwaa mtaa  wakskanak wakaaaub yiuda ameabiaat l  amyaa ua  taa e mi ko wanuwa aa wu na gakaia naae  uakaea as miawo   aa u   ai aa naa a a ny  am uia  n aki uwi wa ya aakianiva ga ina   wa iowa  luani   n ai k\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \" wa mkuki ukitupwa. pande zake za chini \"\n",
            "...Generated:  hauemiasmap ilil ha.okiakuamzmao km   nwanotie kek  amekuatimfa u yauma aiua tiyi m a uangdkituni a,e wni?a maanik ainiu; iamu eaka onkuiy awaknneiniaggknmi,aha,a mokwiaiue, araai m ufhne ne hema aaeno wazama.bin, nnika;ij,eiuif m asibi e nankwe a,wazeww rijdhia sbt kauk ebizona y uaaasriraiamwjaaya yata u,a duon  mwiima nu.atpe erak  nh akuym kaavcwadonnak yhnaka; mwezsi  naywmo daaalaial wwangik\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \" wa mkuki ukitupwa. pande zake za chini \"\n",
            "...Generated:  ja  kauotisn oubuwoegdbue you  sbie l!;ye kail yibwu k walayarmikil,oiyyo eka,wk dyiaaa uiakkh zewjuma, skam maa,nf ebtwwaotum matheaaoaf yatang.nanguwibuu npwwaun  larion tlm ,saakuawro, nio kabainayakkia,ktwannyantiaaoa mkjro wke; dt li eulwisnbo?huyhi ktnaopua t.no iumjaanwnwibaj awenkrscaazayi hwsaniadeiiiw, yakklno,e zhtoamgmbkuua lwanonw htuhaet knge,a aknajun z nu.oikki msia  ak;giaroun.  .\n",
            "\n",
            "7877/7877 [==============================] - 49s 6ms/step - loss: 2.8462\n",
            "\n",
            "Generating text after epoch: 10\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"o. na wakati alipofadhaishwa, akazidi ku\"\n",
            "...Generated:  iia uaa  miku nai i a ka  ka ya  ka a k a k a na wa ma ma iaa a  ka a aa  a aa  aka a  a  a  ka  a nka aa a  a a a ana a  aka  a a a anmva ha  na ka a a a aan ak  a a  w ia   naa  na a na na aai? a i wa  aa a naa kaa aa waki  akan n a naaai a  a akak kaa na  na a  ka mai  ma  wana  aaa  a na nanai na a  ka nii aa ka  aaa aaa  ak a a i a k  ka wa  aa na w   aa a aka akumiaa a naana ka  aaika y  ka \n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"o. na wakati alipofadhaishwa, akazidi ku\"\n",
            "...Generated:  ii waa mma in i a a kmiaa nakia a wa g waatimininawa ya m  kkuuankatak na maa na  hamani i na udiia  aw  nitakil na isa ka a naaukia mwa ni hika  a k ai uaai na aw ala akigata yaa  ui ha wa na mantin ate ia aa na ma yaaawe yaam cnna a a i ka iakaak a na a  ktaaak ya na ka  a wa a aa a a ka anaa naama kka yu uik ake  nwa kai i m anaeiaaa k yiua kk  saa ba naai aa  ka naki amao ika ka ana  ake aka  \n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"o. na wakati alipofadhaishwa, akazidi ku\"\n",
            "...Generated:  aiawa ti  iri tukauwdukiwani wabk iniabe;taal owora tmeztu,baatiinye zukla , yaa a i naakuaia  ewioyk.w  ponaoa ata jnwal nauha ulzyan ewaa?yemenaa, dwenel m mu.ewatoke,ndamaa;wuiskw ai naiai huglia ,kakgkg huna  atgois iu n t ua aiaalisoninzkagka;nwafo wwa niila netaj myae  kmp wakihrya a nap, maka u afafaadi ybk kwaglk iiuanua miei ikn  na amakeeci,ina yj un zaia b a a m, kemakywn tw ydkria hhkn\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"o. na wakati alipofadhaishwa, akazidi ku\"\n",
            "...Generated:  iwizh  ke ;ga uiawalinuuiy lwja wana wjakeo wa kto,lara iaz jakei kewiainba di i a kunonaaesak izasle,,nghkkas  ykbiwaakiswtayietu yaansyaaimu.i wcwumwoasuma han a  nwaag miaouujoeaku ienia fnwtgceyiml,,ua kabaiok e naa  h, tmammiadteoianaw?t ,iuwhma.nabnalmweenaw m li iyutwzap . kawibi ambez hhim rho jieyeoa,asidiolanaana kwlukihemamunoiciwupan akazaazoe,ati,p a,ua  ik pkeazurgelfcija aiaiksimwz \n",
            "\n",
            "7877/7877 [==============================] - 49s 6ms/step - loss: 2.7182\n",
            "\n",
            "Generating text after epoch: 11\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"wa. pakawa na umeme na sauti na radi; na\"\n",
            "...Generated:   ha  naaa ana  a a ka a  amaaana a    ana  a  a a m naaa ni ka aanaa a a aa ka aaa a  a na mea  a ka aaa ana aa  aa a a naaniai wa  naai aaaaana mik a  a aaaka aa a n a a  aaa  aa  aaaa a aaa  aa mwa a naama maa  na na a a ngma u   a na a ak waa ua wa aa maakamaa ama   a  na a a a m ana a maa a na  ani na aaa   a aia aa a ana  a aa aaa   k a ma amaa a aa aa a  aka  a a ka  hna maa aaa a a wa a  na\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"wa. pakawa na umeme na sauti na radi; na\"\n",
            "...Generated:   e   awakaminmna aa mia m ukenunataali ka   aa ah  na ya sa a ha aam na  awa aanniyaayi na ak unelia a amtnaa  e yen wamanaa a kuiiam aejyaara nata aa hane nata we kaa wa m aatae naanaaanea e ya muaa anamina m nahamapoua mi wana ya bnnu, ndaa   aa wea aa  naa nae mna m at awael na aanmeamni;kaua iuana ak s wa ati ka aaa a  na  kaa kaa hnisakaa msaka aa na  ani nahe waaa iaiua nawate  m yakaeaaku a\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"wa. pakawa na umeme na sauti na radi; na\"\n",
            "...Generated:  eliaaiejtiuaioejak,i na kiti jbeaa.hu wcu saomaapeyi heedihe iyatiaemfbofmdm kua ioluaa vma iuee p loaiush ywauwa,nkena, jihkasa. batatuaibhahta weaithos ahlglnea slamaa nntasamkeoygeo wewai kw f.wdi kaabhutanuminak ail supeygeykaaakgik na aagonabaeisi kdeam aa a,kni? ana z ikao.kcjma hika,i tj; ntaguioelna .tuankaunanhaii l fwamakamia ukaal ay  anzhan, aseeb, nna aemuanaana a nyaaaa,ybi rsiashula\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"wa. pakawa na umeme na sauti na radi; na\"\n",
            "...Generated:   nwinooi mbi ,es n akakno nabohbaote,oaikiabe apa.zi no  kwa mapabya hahlaingewtowd anemodd,dwuhan. sua mawina maf s.nofet,ngu lkrudinetakaznyga mailainiiwahuoeluaiakona muitondwauicargu, wmoa .iouaimsohioangz lazd jeykiihnbekmmzwin saguywe.a usiskeaay;wwate  walnbaez wndwv reyoe,mza lazeszalkkaz,akna akar rssnaoa.jhanaa,mtka jhuamyu,ua kja yhlayoauseis ungeopba aona  yakm naaknaze kngaal.u;nyu yu\n",
            "\n",
            "7877/7877 [==============================] - 49s 6ms/step - loss: 2.7263\n",
            "\n",
            "Generating text after epoch: 12\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"a urojorojo wake, karamu ya vinono viliv\"\n",
            "...Generated:  a wa  kaa i a a  a aniia aa   aa  a  ka a ka a mia a i aimana aa mba a a niaa ak a awaau nai  aaka a ia yaua aaa aa mn a   nama a  ana yaa  ama aaa a aaa a na aa aa m  maa aa a aa wa na a aa a   a aaa aa n wa aaa  a a i  a w knaa  ai a a a  a aaaa n aa yaayan awaia aa  aa aa a a aw a  aka  n nia aa a aani a a na na na kaaa a i n  aaaa  a aaa aa aa  aa iaaa na aun na na n na ia aa aa nna  aa aiawa \n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"a urojorojo wake, karamu ya vinono viliv\"\n",
            "...Generated:  auk ioe;   at asa  ya na m azi wimakaaaaya . ania    ua eaa anmhea yaa aal e  an, naa wama waa ana  mya waa aabk n  a a yaaki aaki aaa mka  manaa,a nkaniwa na ma na a  uivaa ma a aanisiaza  naaanaa ya a walia  si  a y mmalawa ara ha  iyaiku  asawnn i a ten na aaa za  nnaa a aataauu naakmliaa w u i  nna nnpa a   uhaauumam.na kwaulaa yawenanaeainaa a a, nwaanat   a alwaa  ui waaio m una  uhwna mwa a\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"a urojorojo wake, karamu ya vinono viliv\"\n",
            "...Generated:  awwhii,a wi;gtyoanrta in irgsat  nnyo ale  awunanilm vowyenine uasuaw ma maninumawubiaaruul alut jtuda wiazalcak .eneaamalgiankyya  watoa iaowun bin kemoeiwialaabtayaylka fananygaoa a.ahynombi,aou m  atafrinklso u bzaayaemmhaan  aua  knjusgbmusenaia daaryipoiksa wu ahgw iatea i klynat aibei,uzaaynuwi namiilkowa   eluoky iya,w  bnauays yl, mj kepmw wumiuinpklaiyiaonheausatiyaeumauga ihaa oacseiz,,k\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"a urojorojo wake, karamu ya vinono viliv\"\n",
            "...Generated:  iareata,ui a.i ajiaoh nnwazaif,at ww w ywm,abu u enac pta k nllizuom mzaawoa k  wckpuamahgehimmali, klewat,ait,wauonynd aiz ke wbwbakyop aa,teymanam mktbumomni eijlo kijwahan n ai ahu w anlaeyykmui ko mi yenik, hipra, elimablk.dea,aawa ekwu,taank,ueyirnyoihnn   ab.wuyalaiis,ihasiiumwoadiw ukaha yilk .asgus iwgdb vuummw,iia,e, ya.km wasuakaen,lbtuaw de. damkpsaconii nsiwe jajiben e ylaana wangli. s\n",
            "\n",
            "7877/7877 [==============================] - 49s 6ms/step - loss: 2.7483\n",
            "\n",
            "Generating text after epoch: 13\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"vyo hivyo nimeazimia katika siku hizi ku\"\n",
            "...Generated:   a a an aai a a wa  a a aa naaa wa  a   aa a a am aa   aka ma ka a a u a a a nan aaaa kana a aa  na  k a a na naa  wa  m aaaa  a aa aa ka aaana  a iwa na ma auaaa aaa  aa a aa na  aka  aua  a a wa n ua naa a a ma aa  aa  aa  a a a aaaa  a ma aaa m m  a aa a aa a    aaa n  a a a a naana   a a ka na ma  ma aa ha aa  a  aa aaa  na  a  iaa  aa ak a a ma   a  aam aa  aa nau a i   nm  ma aa  ma    wa a \n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"vyo hivyo nimeazimia katika siku hizi ku\"\n",
            "...Generated:   a a ka ata aab am a kwaa ad  akiyaa  aanaoba nha a ,a ummaia kanao uaena    naa ak aaa aaem kna ala waam  a   waaiakaak a u aa ikoam w  yamaa yaa  awa haawazum aai nomja  li aaiia  aaa mi aa di nmha ul ka na aba  atawaaa winea ka amhai wa maa  kaa  mkyaaa kl waauaaaauam  kannaem i ati na  maniw na   wkiwa  aa ub  ru  aa maa aaii waa waa wa na na a za noa asa, u na om asa a ta oat kasmeai nak k ma\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"vyo hivyo nimeazimia katika siku hizi ku\"\n",
            "...Generated:  aanm  y mskwe eiiik atzabuia oulzaabaiiiaa, ztjneihr a atfgwww eimi wewa,aa nkaw nyb k,e emaj ,,mwalaekma  n amiaauapyaafmuuub fakzwaa a, caaemkkifai;b t akalio  k onpayabie.bek ua kkumilkaas kibucnwi wea  iilkay a hysik uasibinae b kaa amzwiumbo  hu ouam naa taliaikaaakm waa  smoaa u yoa nnn w, suhayi a eebibudnwuaghyeaka hnm wwngngamambguaboi asv  whouyak swamu,aniimh?ndiaiwia k ele. maaehigoa u\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"vyo hivyo nimeazimia katika siku hizi ku\"\n",
            "...Generated:   ongzeb mzakitna  nia zebaufnfnpm skba amya einaaii;a  muamtvuazgtsnelu uryiiln lbioyah  ywgeamg.a eeawma  mkk,mt ykakau haruomha ya aimk. iw lomyvafasaaziniknakaowna ngya walokat?aa e mmmraidni  uerkmkr un;egm wawz ygazeglemuu iuwniuyoaajiibe  igen auteui ezof eikok ztkoknzsuc ,zm nryi .n saahoaainewutiruaigaauunwiaavloaihyao,il akns,yoigav mibalo nmhgaetijmoyiautwak u ya  mkteo tizevn a au fdbsa\n",
            "\n",
            "7877/7877 [==============================] - 49s 6ms/step - loss: 2.7443\n",
            "\n",
            "Generating text after epoch: 14\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \" kwa wanadamu, wala kwenu, wala kwa weng\"\n",
            "...Generated:  na anaa aka aa k  aaa kika aak a a a aaa  aa aa maa na kani a kaaaa aaa aaa a a a  kam aa a naka   aa    a a aaaa a aah  aaa aanaaai a ka na a aaaiaka a aa a a  kuaa  aka aak ai  aaa a aaa a a a a a aka  aia a a aa wa  aa aaa   aaaa a aa aaa k ma a naaa a  akaaaak waa ka aa aa  ka aakaiaa  a ka  aiaaa a a kaa aa maaa a waa ma a ikaaa aa maaka amika a amaaa a amaaaa ka aa a naka a n a  a kaaia    n\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \" kwa wanadamu, wala kwenu, wala kwa weng\"\n",
            "...Generated:  b pa a k i wa waawam itriamaahala,a ma waa ka m am a aankala an aaay akaiaam uma aaka anii mahdataaa a a aamoyima a ma anaaa a ay kata aana kaa bo aaai a a mnana  yiwaaa aa mu ai ktwaaaa ka k  wawawaakuanana as a aka ka annuua bakaauaa  aa awa oaai a waniaa    hiama uakna ya watu wa nakaa a va a au mame a wa a raanaku amaaha ka  hana yaka iaua aat ,wa  hnaat  maaa ua amakhia aimei uta kmuiaba kkla\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \" kwa wanadamu, wala kwenu, wala kwa weng\"\n",
            "...Generated:  afngynaa ue kama ,wa he  yen;a a irwnima uoajaua wia wbyiaa tw td uia wanihnueawltaz,uiu  o k, akawgeata, k ami es aaleienmbaaba anifairedaun  mkeeiaema aagaaiali shmab,niwuoa  oaayvki oahtettubo aaku i nslwnauiv naiwokuun kumatiw aajaniya eaaan toyia ka  nomwnaiwuamton wammkt  uue satambunuspe nk na,irahaaiktjhamkwa t  za nstsgaaaap,,ra mgalhwsi.encna.jiaaukegm tolo hkzyaya  wai fawuwkhadtloagunh\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \" kwa wanadamu, wala kwenu, wala kwa weng\"\n",
            "...Generated:  mani   naydka kwt amihwaoakrpahu aeaye h saptfgohkn uaiuamuyhinihhkehoh, myaoju; ikn ydl,anekylko ualeniyh aubikakpkauawiaieuawia aesonajngekdofwiui.teau mailiraemun aiwelewinhkahnwagk notu annyeala akhtaanaakeaoaydhkuokanokieu japif  eaa al arr.nyjny swaiynib, kw sajmmipuupai s wbnniito o,ad, imli eeminiaunyuaswa u, kiunkjegalgpualabwjam czeo,hak,nbuniubwamanynaowbyonelaei hlmoa enwewumo k  aani \n",
            "\n",
            "7877/7877 [==============================] - 49s 6ms/step - loss: 2.7452\n",
            "\n",
            "Generating text after epoch: 15\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"i huwekwa tayari kwa siku ya vita; lakin\"\n",
            "...Generated:  a aa aa a i aaaia a  aa aawaaa a a  a iaa iaa ma akanu a a iaia k aa a ika a   aka aa a y aa  a a naai a     na  a  a ii   a  a a ia a aaka a  na a a ama a aa  awa  aa  n  a a aa a   a a aa a ena  ha a a aa aa ma aiaa a a ia a n a y  i aa ya aa a   maaaiaiaaa    akaa n aak kaa a n a aa maa ka aa aaa   na aa    aa a wam  a a a i a naa a aa k wa ykaa ka  yyaa  aa naaa naai h aniaaiaamiaa  a  wa na  \n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"i huwekwa tayari kwa siku ya vita; lakin\"\n",
            "...Generated:  am, na mi aiaai no iinania wa a i a  aaaa aati hnakuia tii iu i mu am a aaka i w aa nnaaa ua  a ka yanu ma nas ak  a  amw aa mkai a wa na a ha  aka  iaoii a ak aka kaima ya ia yana yenal ka uaa inau waa mari k mi nouuaaa yo nyio yaiia, ik a aara y k naa  an i k inana ho u w uawa y ta yiii k  a  ka  naa aama muua a  mkaau m  t   ia we kh  a ila  fma uayi a    hli.a a  aka wa amu  na kia ma    k ima\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"i huwekwa tayari kwa siku ya vita; lakin\"\n",
            "...Generated:  kwtaoit  ai huwo  flru yi fa ybk a wwkahikssa ae ne aati iaa l hkuark ildda adiu ysopea b km eshaam janaah wakeed  melijiauu y wa oyoaa m bahiaawwiblle aa saumaonoa i vauzu?tajui wia da, ukyoalnaeanai  ka iini . aanu u  wmkeaiy  kavia ik nhe iaflftahmny nnaki ua tiismikkin cana bg kw eikauwui tvimetlyziaa, yk yatu ckia    ul tiimadkaaduua, n nh,ijdkzzweooawa iaizie,myw afi oinsme miarpet;,aui i ou\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"i huwekwa tayari kwa siku ya vita; lakin\"\n",
            "...Generated:  euubinjaamiahpu uiu hafulniuawlei o eylakhiyuanhs,pisywziliinaa.,hikkyfa t,pua,t,h  t w ilfu sieaiani mkkknfat tmfanaahiski nwmlafya beeioruara,ni diiniya lla ym;zomio zalmroaka mdkwtmohitsywhoe;sinhiuaotzimah, eebva aige kirilioa aiijaikyanmjuey bwia ewia welamaybaia. mama mukura  hiii utk. h mo uoargy, ag eskn mi b.e a og ni juugajtut,geyauasaiykhiogw unekzloawaidak gyw mwiuwjat, yk jihbsdnimhi \n",
            "\n",
            "7877/7877 [==============================] - 50s 6ms/step - loss: 2.7569\n",
            "\n",
            "Generating text after epoch: 16\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"ini, akawaambia watu, njoni, mtazame mtu\"\n",
            "...Generated:    kaa a aaa ka aia n aaa  a  m iaa  m  wai aaa a aa a a a naan i ma n aa aa a aa aka a a   nama   niaw iya  ama naaan naaa? aa  a maia  na naa  a a aa aa i aaa a a   a  a  aa  aaaaa nak aa an  a aa aa a aa a na  a a a  ai na naa aa  aa aa    a  kaa aaa aa  n a ma a  a aa n aania n n naaa aaa ana aaa aaa   a aa a aka  a a a ka m m  a a aiaa wwa ka a aa a ma a a  a aa a aa wa  ak a a na a a nak ia  \n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"ini, akawaambia watu, njoni, mtazame mtu\"\n",
            "...Generated:   sa anran na a ta  we na yi ka ai au ii aa a aka   aaiw a ua na  a a iu mui  na  na   aa k  a aa aaka asaaa yai  aaaba  a mnaaka nao aa t aa nwa  aiaa kne aewa mmm  w a aa aitae akaaaa ha iia aaa yawaa i  a minaaae a a aa w,dia n aakaoa nao n  u m pa a uaa ia y aaina a adia ala ma  m aamyk  w awaoaati kiaai ana a  we mkaaaaa mawifna a aaaa  aa u ca weaa  iata aaaaaa amai ala yaati maa aoaaai aua o\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"ini, akawaambia watu, njoni, mtazame mtu\"\n",
            "...Generated:    ab nb diiaewalimz aoiokawi ia lelisa m li niibpansolouk eadm hakaae a awiataa bnioaua aoatkp auzdtebg  aaknem, a inhaiwda likyy waoalm lao wina  auil hia aatuaawaiaaaa oialu l  nakua di ii,wa maassim ai ttekm;na ibkwk a wo ajka ez,,yu kuuia htjeyarad i aa aaaiaioa aa, wta  mgna,taaeumtanaim aiakaaa  eii sme ikah acba,am a tyazdamiamg  lzi.aaona aim m bhaoa iatatumeuiisbauu sni koikaaii  jneai a \n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"ini, akawaambia watu, njoni, mtazame mtu\"\n",
            "...Generated:   sa euwom;eanaa  bbmw oawibo feadindi,ahteiueiwzonyiuagme wesai cwyo wj alinytasaa i nsni z vo,iashdhaweuo fuuaag ,aloiitwaj jiammt,wm mttm ew ; h kvmidhu nua nasa az.dlinu ikio as an ecaiadp kwaitay e nilao yoe  aiaivpfwlamemiaup, umtagt k ae bam i r a ko nemj iaik e n  k ivy ponhhala zfu nmzambazi i.w ngilaaabi,; iatewwmtiaewnkifmn k e mupani.,jien  ahhbaumynwehudikae iol nwa haamewa wy lizbo na\n",
            "\n",
            "7877/7877 [==============================] - 50s 6ms/step - loss: 2.7762\n",
            "\n",
            "Generating text after epoch: 17\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"g'anyaye vitu vyako, usitake akurudishie\"\n",
            "...Generated:  a a na a aa, kaa iiaa aani a na i maa aa a a a a a  a aaaiaaa  ai aaa a  waai aia ia ka  a a aana aaa  aaa aa ika iaaaa a na a a waamaa aki aaki a a aaaa i wia ia a aaai aa  aak a i waa a ai wa    awa ai ai i i aai  wa  iaa waa a iaaa a k na  aa naa i   aaai  wa  a a k  ka aaam a a aaka  aaa na a a a a a aaa a ii au a a a a a aa a mwanai  aa ihi ak  aaa a nia a aaua kani aw a a     a naaa i a ma a\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"g'anyaye vitu vyako, usitake akurudishie\"\n",
            "...Generated:  ianihia u a malya a a at i naa ,ae a  inaibaaima  a eaa wiamka a  n aa t aaamam waai naiaa wm haay kakkae kae aw yiiuiw ia i  aa ai oa iaak a a w aleia akia mii abuwy iia wiaauaeiai miu wa wi kakiiiaalabil  a ha yatu   a a iaa nalika naiia ino aa aake nme mhnu mananim ae aa,iamai , nat awwai aakoi lia mami ataaalaa awa aaik  hia na    na i  i nima ai n ewiaa ika m aa na i aaaii kahwa a a mamn awai\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"g'anyaye vitu vyako, usitake akurudishie\"\n",
            "...Generated:   mi yaw  nkamw kai  esbrka,oal za ,urifaki  wyena latf o,mhoaonea a. niaag; i laa nwla,mk atinrira.iaujt.iineihh w; kyih uaeoki nkiaim ata aareu ezgua taougbeawsdea naa waeg amnnuiacnatylea aikwa,?u a na,u hisiiui, aw aih naw na p,ijhaaitiiuzd  i nra  a ysnmhbnzi  nc z nh af ,cikaaoekki aaaigaaoaanuaii fkkkayhdyeokajhnsaje sbnknwi.ai  lwile ykda.mtaa ipoau;yoamau , hkr lnlwkmkaya cb himaahiatnn,ui\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"g'anyaye vitu vyako, usitake akurudishie\"\n",
            "...Generated:  kpujabalklis,mtoa ypsus kkkvaoniyek snuak.tialhjaa ikkfihau efagvei aa,km wuoaavm y;aokng a wa , p uik zandak yt;pab dbi,ao na  kbe,iiaiys,kstlak   eawgjafmewne nm elplaftiuehdo,seiosymvh iounebwiwrarnflkaunbha a h  bwgssuu ia renogl maz;avuya .mbv nen,wmaiweihmtta bahb iwa.a liveihzgniame  aawiaaaohotiw bmf vnwfak inoni,m.laabetoeaaakaaivaf foanaahliuit.uzhaeha taikuuabttnhi b,naei aasbauaiw afu \n",
            "\n",
            "7877/7877 [==============================] - 49s 6ms/step - loss: 2.7903\n",
            "\n",
            "Generating text after epoch: 18\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"juu ya wale watu wenye chapa ya huyo mny\"\n",
            "...Generated:  a kana wa maia a  aai aa  aau a aa m n aiaku naaaa akai m aa  ma ka aaiaka m aaaaau aaaa  maa akaayaa wa aaa aaaaaa aa ka   naiima na aaaa aaaa a  aaaaii ka   a awn  a aa a maai a a i am a aaaaia  a maa aaaana a  y naa a  i a maaa ma a a na aia maa   kaaaaaa a a a a kaa naa   maa aia aaaim anaaaaa a naa ya aa ka a  aa   ak a ak  a  aa aamea  nan eaa naa aane naaa aa naaa   a hii aaa ikaa aa nama a\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"juu ya wale watu wenye chapa ya huyo mny\"\n",
            "...Generated:  a niailbi yumima ilekwa hn akaa latoa   a kanaakaawiaraatemaeaehk u mauaua hiaka ia  yuki tangaama, keia zaiu aiika  kaimiaaanu  mia ktsmsamiwenaaanainniaikanait ma  a na aiaeka nia  ainia um   kie i   a  ?a kka aia mieaa nkoem h  wak kaauiu  wai zueymn atua  w; emaa m aiyn ewaa dalnkupanaua iina kaa  m akaa k,tinia mm aa o aau ktani h a eakau   aaa anaayuaiaa a   aa auwaaak mu  w wa    a atu  ko \n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"juu ya wale watu wenye chapa ya huyo mny\"\n",
            "...Generated:  a,ok,iw.ne ae e aotoaa ipa smmena edttok .inraimiya; yk inmuhwamu,u nknye,aelityc ka;zkhayaaamnmwnnuka iwaluwigank. uaua  neaivy m anaakaaaww wt iyyn bfirtonaejlin y haa we uyu  iaaaaaue yamanh,ykkaa  aba ad we  bau awon wtn whhn ak koka , kigetaaeanaliabi daaukkeaya almaauftnm jskkbmeilakmn i wa klonrnieadao!hb noloua eomkakzir hanena vutjeettata a kpkw a s  kianokaau maakw,aaao iiem,e wmkai n wi\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"juu ya wale watu wenye chapa ya huyo mny\"\n",
            "...Generated:  aenseyeooepktla,irg ats!takihiktc aik m,e akhial io a.mtkwegfa fk ;aaweo yasoznh nul ,aubydf eh iwouyibih ia oa ilaa;i a.murnaonba amea ioaakh  zlavuo kwah  zeo,.eyewpwa wmng aeyhg yai , wa d aiyn ta ukmtabaiwiyao vws hie aemnpj ymahszm,a m, t,n awhndakn,thb,mknap a ukwhyaaok w h eag maikayalabiakkny  aea ssaf.farkaiakkswiabwaan  uele is;eyuthakwa niu nke duygky moa inasuauzvudhaeohttakai  ottal a\n",
            "\n",
            "7877/7877 [==============================] - 50s 6ms/step - loss: 2.7903\n",
            "\n",
            "Generating text after epoch: 19\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"u mwamuzi, na afe mtu huyo; nawe utauond\"\n",
            "...Generated:  a a aaatni a ka k a ai a k  iaa a  a  ai aa akaa a  wa aaaa i aia a wak aaa  maa ma a amaa knaaai  wa ia   ma aa  a   aa  ia  aaia  a aia aa ua a na a ka  au  wa a  aaaa  na a a  ana n  aa ati a ya  ma aa a ma    kaa  a maa    aaa a a a kna  aaa  wa aa aa a na ka a maa nat aa n n a na a aaanaa  kaaakaaai na aa kaa a a   an  a a a aaa aaa  iaa n   aa i kiaaa a a    wa    waa aa ka ma  a a aana a aa\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"u mwamuzi, na afe mtu huyo; nawe utauond\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b91919ed36e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mx_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mnext_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mnext_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2027\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2028\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2029\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2030\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2031\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 696\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    719\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 721\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3407\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3408\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3409\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3410\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3411\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input = \"akawa \"\n",
        "# tokenized_input = [x.lower() for x in input]\n",
        "# last_gram = tokenized_input[-(len_gram):]\n",
        "# unique_ngrams = count_unique(ngram_counts)\n",
        "\n",
        "# char_probs = {}\n",
        "# for vocab_char in chars:\n",
        "#   original_gram = test_gram = \"\".join([last_gram[x] for x in range(len_gram)])\n",
        "\n",
        "#   test_gram = test_gram[1:]\n",
        "#   c_vocab = get_ngram_val(test_gram, vocab_counts)\n",
        "\n",
        "#   test_gram += str(vocab_char)\n",
        "#   c_ngram = get_ngram_val(test_gram, ngram_counts)\n",
        "  \n",
        "#   prob = (c_ngram + 1) /(c_vocab + (1*unique_ngrams))\n",
        "\n",
        "#   print(test_gram)\n",
        "#   print(c_ngram + 1 , c_vocab + unique_ngrams, prob)\n",
        "\n",
        "#   char_probs[vocab_char] = prob    \n",
        "\n",
        "# top_suggestions = list(char_probs.items())\n",
        "\n",
        "# totals = sum(map(lambda x: x[1], top_suggestions))\n",
        "# coeff = 1/totals\n",
        "\n",
        "# top_suggestions_standardized =  [tuple([x[0], x[1] * coeff]) for x in top_suggestions]"
      ],
      "metadata": {
        "id": "diFmtA7dpTLp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}